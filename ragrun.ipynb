{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai (from -r requirements.txt (line 1))\n",
      "  Downloading openai-1.56.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting zhipuai (from -r requirements.txt (line 2))\n",
      "  Downloading zhipuai-2.1.5.20241203-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.21.0)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.19.0)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (2.4.0)\n",
      "Collecting transformers (from -r requirements.txt (line 8))\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (4.66.4)\n",
      "Collecting PyPDF2 (from -r requirements.txt (line 10))\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: markdown in /opt/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (3.4.1)\n",
      "Collecting html2text (from -r requirements.txt (line 12))\n",
      "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tiktoken (from -r requirements.txt (line 13))\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (1.8.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai->-r requirements.txt (line 1))\n",
      "  Downloading httpx-0.28.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai->-r requirements.txt (line 1))\n",
      "  Downloading jiter-0.8.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (1.3.0)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai->-r requirements.txt (line 1))\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: cachetools>=4.2.2 in /opt/anaconda3/lib/python3.11/site-packages (from zhipuai->-r requirements.txt (line 2)) (4.2.2)\n",
      "Requirement already satisfied: pydantic-core>=2.14.6 in /opt/anaconda3/lib/python3.11/site-packages (from zhipuai->-r requirements.txt (line 2)) (2.23.4)\n",
      "Collecting pyjwt<2.9.0,>=2.8.0 (from zhipuai->-r requirements.txt (line 2))\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 5)) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 5)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 5)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 5)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 5)) (2023.10.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchvision->-r requirements.txt (line 6)) (10.2.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers->-r requirements.txt (line 8))\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 8)) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 8)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 8)) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 8)) (2.31.0)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers->-r requirements.txt (line 8))\n",
      "  Downloading tokenizers-0.20.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers->-r requirements.txt (line 8))\n",
      "  Downloading safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (2024.7.4)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1))\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 1))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 8)) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 8)) (2.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 5)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch->-r requirements.txt (line 5)) (1.3.0)\n",
      "Downloading openai-1.56.1-py3-none-any.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zhipuai-2.1.5.20241203-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-macosx_11_0_arm64.whl (982 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m982.4/982.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.28.0-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.6/447.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.8.0-cp311-cp311-macosx_11_0_arm64.whl (310 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl (381 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.5/381.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Building wheels for collected packages: html2text\n",
      "  Building wheel for html2text (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33110 sha256=42d892badb784c9051c8208d0eb6e94ec8e486a647052ed7f3bd00773252ec5f\n",
      "  Stored in directory: /Users/mengzhang/Library/Caches/pip/wheels/23/58/7c/d9c8c4d924a1ac2b621add1b2c1d30b639629a33cfdfde6a45\n",
      "Successfully built html2text\n",
      "Installing collected packages: typing-extensions, safetensors, PyPDF2, pyjwt, jiter, html2text, h11, tiktoken, huggingface-hub, httpcore, tokenizers, httpx, zhipuai, transformers, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "  Attempting uninstall: pyjwt\n",
      "    Found existing installation: PyJWT 2.4.0\n",
      "    Uninstalling PyJWT-2.4.0:\n",
      "      Successfully uninstalled PyJWT-2.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.30.0 requires packaging<24,>=16.8, but you have packaging 24.1 which is incompatible.\n",
      "anaconda-cloud-auth 0.1.4 requires pydantic<2.0, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyPDF2-3.0.1 h11-0.14.0 html2text-2024.2.26 httpcore-1.0.7 httpx-0.28.0 huggingface-hub-0.26.3 jiter-0.8.0 openai-1.56.1 pyjwt-2.8.0 safetensors-0.4.5 tiktoken-0.8.0 tokenizers-0.20.3 transformers-4.46.3 typing-extensions-4.12.2 zhipuai-2.1.5.20241203\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API 调用成功，响应内容：\n",
      "Completion(model='glm-4', created=1733321052, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='你好！很高兴见到你，有什么可以帮助你的吗？如果有任何问题或需要咨询的事情，请随时告诉我。', role='assistant', tool_calls=None))], request_id='20241204220411100b8c6cf9814e7d', id='20241204220411100b8c6cf9814e7d', usage=CompletionUsage(prompt_tokens=12, completion_tokens=25, total_tokens=37))\n"
     ]
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "# 替换为您的实际 API Key\n",
    "api_key = \"9223a2c8f75d9915d2d93b6d97d6222a.O45O5wOmiPTgjt3p\"\n",
    "           \n",
    "# 初始化 ZhipuAI 客户端\n",
    "client = ZhipuAI(api_key=api_key)\n",
    "\n",
    "# 测试调用\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"你好，ZhipuAI！\"}\n",
    "        ]\n",
    "    )\n",
    "    print(\"API 调用成功，响应内容：\")\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(\"API 调用失败，错误信息：\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAG.VectorBase import VectorStore\n",
    "from RAG.utils import ReadFiles\n",
    "from RAG.LLM import OpenAIChat, InternLMChat, ZhipuAIChat\n",
    "from RAG.Embeddings import JinaEmbedding, ZhipuEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|██████████| 14/14 [00:06<00:00,  2.06it/s]\n"
     ]
    }
   ],
   "source": [
    "docs = ReadFiles('./data').get_content(max_token_len=600, cover_content=150) # 获得data目录下的所有文件内容并分割\n",
    "vector = VectorStore(docs)\n",
    "embedding = ZhipuEmbedding() # 创建EmbeddingModel\n",
    "vector.get_vector(EmbeddingModel=embedding)\n",
    "vector.persist(path='storage') # 将向量和文档内容保存到storage目录下，下次再用就可以直接加载本地的数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最高感度のアジレント6400シリーズトリプル四重極LC/MS、6500\n",
      "シリーズLC/Q-TOFおよび6230LC/\n",
      "TOFシステムと組み合わせることが可能です。ハイスループットスクリーニングを行うラボ向けに、高コストで時間がかかる、あるいは従来の手法では分析できないターゲットに対し、1次および2\n",
      "次スクリーニングを行うことができます。リード化合物探索やADME（吸収・分布・代謝・排泄）研究において、ワークフロー全体の時間を短縮し、人的リソースおよび資産の有効活用が可能になります。\n",
      "\n",
      "創薬プロセスの効率化を実現するRapidFire365システムの特徴\n",
      "\n",
      "ノンラベルにより難易度の高いスクリーニングが可能生産性と効率の最大化多様な固相抽出法の利用による分析法の最適化短いサイクルタイムによる分析時間の短縮\n",
      "アジレントのLC/MSにインテグレートされ、MassHunterソフトウェアに連動した制御\n",
      "\n",
      "\n",
      "\n",
      "アジレント自動化ソリューションの特徴は、高感度なトリプル四重極LC/MSやLC/Q-TOFシステムと組み合わせて使用できる点、ハイスループットスクリーニングを行うことができる点、従来の手法では分析できないターゲットに対し1次および2次スクリーニングが可能な点、ワークフローの時間を短縮できる点、人的リソースおよび資産の有効活用ができる点、そしてRapidFire365システムのノンラベルスクリーニング、生産性と効率の最大化、多様な固相抽出法の利用、短いサイ\n"
     ]
    }
   ],
   "source": [
    "vector = VectorStore()\n",
    "\n",
    "vector.load_vector('./storage') # 加载本地的数据库\n",
    "\n",
    "embedding = ZhipuEmbedding()\n",
    "\n",
    "question = 'アジレント自動化ソリューションの特徴は？'\n",
    "\n",
    "content = vector.query(question, EmbeddingModel=embedding, k=1)[0]\n",
    "\n",
    "print(content)\n",
    "\n",
    "chat = ZhipuAIChat(model='chatglm_lite')\n",
    "\n",
    "print(chat.chat(question, [], content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'git的分支原理？'\n",
    "\n",
    "content = vector.query(question, EmbeddingModel=embedding, k=1)[0]\n",
    "chat = OpenAIChat(model='gpt-3.5-turbo-1106')\n",
    "print(chat.chat(question, [], content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VectorStore' object has no attribute 'docs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m vector\u001b[38;5;241m.\u001b[39mload_vector(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./storage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 确认加载的内容\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded documents:\u001b[39m\u001b[38;5;124m\"\u001b[39m, vector\u001b[38;5;241m.\u001b[39mdocs)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded vectors:\u001b[39m\u001b[38;5;124m\"\u001b[39m, vector\u001b[38;5;241m.\u001b[39mvectors)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VectorStore' object has no attribute 'docs'"
     ]
    }
   ],
   "source": [
    "# 初始化 VectorStore 并加载向量\n",
    "vector = VectorStore()\n",
    "vector.load_vector('./storage')\n",
    "\n",
    "# 确认加载的内容\n",
    "print(\"Loaded documents:\", vector.docs)\n",
    "print(\"Loaded vectors:\", vector.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 问题与查询\n",
    "question = 'アジレント自動化ソリューションの特徴は'\n",
    "content = vector.query(question, EmbeddingModel=embedding, k=1)[0]\n",
    "print(\"Matched content:\", content)\n",
    "\n",
    "# 调用 ZhipuAIChat\n",
    "import os\n",
    "assert os.getenv(\"ZHIPU_API_KEY\"), \"ZHIPU_API_KEY 未设置，请检查环境变量。\"\n",
    "chat = ZhipuAIChat(model='chatglm_lite')\n",
    "response = chat.chat(question, [], content)\n",
    "print(\"回答:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "VectorStore.query() got an unexpected keyword argument 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mアジレント自動化ソリューションの特徴は\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m content \u001b[38;5;241m=\u001b[39m vector\u001b[38;5;241m.\u001b[39mquery(question, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzhipu\u001b[39m\u001b[38;5;124m'\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m chat \u001b[38;5;241m=\u001b[39m ZhipuAIChat(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchatglm_lite\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(chat\u001b[38;5;241m.\u001b[39mchat(question, [], content))\n",
      "\u001b[0;31mTypeError\u001b[0m: VectorStore.query() got an unexpected keyword argument 'model'"
     ]
    }
   ],
   "source": [
    "vector.load_vector('./storage')\n",
    "vector = VectorStore()\n",
    "\n",
    "question = 'アジレント自動化ソリューションの特徴は'\n",
    "\n",
    "content = vector.query(question, EmbeddingModel=embedding, k=1)[0]\n",
    "chat = ZhipuAIChat(model='chatglm_lite')\n",
    "print(chat.chat(question, [], content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'アジレント自動化ソリューションの特徴は'\n",
    "\n",
    "content = vector.query(question, model='zhipu', k=1)[0]\n",
    "chat = OpenAIChat(model='gpt-3.5-turbo-1106')\n",
    "print(chat.chat(question, [], content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 没有保存数据库\n",
    "# docs = ReadFiles('./data').get_content(max_token_len=600, cover_content=150) # 获得data目录下的所有文件内容并分割\n",
    "# vector = VectorStore(docs)\n",
    "# embedding = ZhipuEmbedding() # 创建EmbeddingModel\n",
    "# vector.get_vector(EmbeddingModel=embedding)\n",
    "# vector.persist(path='storage') # 将向量和文档内容保存到storage目录下，下次再用就可以直接加载本地的数据库\n",
    "\n",
    "# # vector.load_vector('./storage') # 加载本地的数据库\n",
    "\n",
    "# question = '正向扫描的原理是什么？'\n",
    "\n",
    "# content = vector.query(question, model='zhipu', k=1)[0]\n",
    "# chat = OpenAIChat(model='gpt-3.5-turbo-1106')\n",
    "# print(chat.chat(question, [], content))\n",
    "\n",
    "\n",
    "# 保存数据库之后\n",
    "\n",
    "vector = VectorStore()\n",
    "\n",
    "vector.load_vector('./storage') # 加载本地的数据库\n",
    "\n",
    "question = '逆向纠错的原理是什么？'\n",
    "\n",
    "embedding = ZhipuEmbedding() # 创建EmbeddingModel\n",
    "\n",
    "content = vector.query(question, EmbeddingModel=embedding, k=1)[0]\n",
    "chat = OpenAIChat(model='gpt-3.5-turbo-1106')\n",
    "print(chat.chat(question, [], content))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
